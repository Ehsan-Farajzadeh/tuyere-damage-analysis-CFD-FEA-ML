# Tuyere ML Analysis Demo Notebook

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# Load example CSV (replace with actual filename or path if needed)
data_path = "data/example_dataset.csv"  # Replace with your actual file

try:
    df = pd.read_csv(data_path)
except FileNotFoundError:
    print(f"File not found: {data_path}")

# Define input and target features
input_features = ['CO', 'CO2', 'H2', 'H2O', 'Heat_of_Het', 'Het1', 'Het2', 'Het3',
                  'N2', 'O2', 'RR2', 'RR3', 'Static_Enth', 'Velocity']
target = 'Stress'

# Clean data
print("Original data shape:", df.shape)
df[input_features] = df[input_features].apply(pd.to_numeric, errors='coerce')
df = df.dropna(subset=input_features + [target])
print("Cleaned data shape:", df.shape)

# Train-test split
X = df[input_features]
y = df[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost Regressor
model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
model.fit(X_train, y_train)

# Evaluate model
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")

# Feature importance
xgb.plot_importance(model, height=0.5)
plt.title("Feature Importance (XGBoost)")
plt.tight_layout()
plt.show()

# Correlation Heatmap
correlation_matrix = df[input_features + [target]].corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", vmin=-1, vmax=1)
plt.title("Correlation Matrix")
plt.tight_layout()
plt.show()

